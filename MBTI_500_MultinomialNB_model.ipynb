{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqbUc/7hgmDQ3UdGJ6P4wo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aksanaboo/persona_predict/blob/master/MBTI_500_MultinomialNB_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "egOX7gE_7qy2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import pickle\n",
        "import os.path\n",
        "import plotly.offline as pyo\n",
        "import plotly.graph_objs as go\n",
        "import spacy\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "T7tIkyCB705u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yCZq3DK72sL",
        "outputId": "aca9620b-3e5a-4c72-f3e6-062fbbbb1fa9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mbti_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MBTI 500.csv')"
      ],
      "metadata": {
        "id": "CXDwhf617471"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mbti_data = mbti_data.rename(columns={'type':'personality_type'})"
      ],
      "metadata": {
        "id": "DmQdsz8x8Dik"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recreate_model=False"
      ],
      "metadata": {
        "id": "QzKslpKN8FQr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'mbti500_MNBmodel.sav'"
      ],
      "metadata": {
        "id": "O8tc-PXX8HPt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(filename):\n",
        "    recreate_model=True"
      ],
      "metadata": {
        "id": "ZcKV8AIS8Nwp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = mbti_data['posts'] # features\n",
        "y = mbti_data['personality_type']  # labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "prKhFfxP8PNE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if recreate_model:\n",
        "\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Preprocessing and Feature Engineering\n",
        "    # Apply text preprocessing here (e.g., cleaning, lowercasing, lemmatization)\n",
        "    # ...\n",
        "\n",
        "    # Creating an instance of the vectorizer and training it\n",
        "    vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')  # You can add more parameters\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "    # Training the classifier with tuned alpha parameter\n",
        "    clf = MultinomialNB(alpha=0.1)  # Experiment with alpha values\n",
        "    clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Pipelining the vectorizer and the classifier\n",
        "    text_clf = Pipeline([('tfidf', vectorizer), ('clf', clf)])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "\n",
        "    # Save the model to disk\n",
        "    filename = 'multinomialNB_model.pkl'\n",
        "    with open(filename, 'wb') as model_file:\n",
        "        pickle.dump(text_clf, model_file)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_predictions = text_clf.predict(X_val)\n",
        "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "    print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Load the model from disk\n",
        "with open(filename, 'rb') as model_file:\n",
        "    text_clf = pickle.load(model_file)\n",
        "\n",
        "\n",
        "test_predictions = text_clf.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm05WWun8RBW",
        "outputId": "692bf94a-f9fd-44e6-fd2d-72451373bcec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5812794612794613\n",
            "Test Accuracy: 0.5893592281826466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = text_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "hGvw-ETQ8UmH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE0cbUni8WmT",
        "outputId": "8a12fa16-a85d-4ec9-ff3b-9dd7f1d2778e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       1.00      0.02      0.05       484\n",
            "        ENFP       0.93      0.09      0.16      1834\n",
            "        ENTJ       0.99      0.17      0.28       907\n",
            "        ENTP       0.76      0.28      0.41      3494\n",
            "        ESFJ       0.00      0.00      0.00        54\n",
            "        ESFP       0.00      0.00      0.00       103\n",
            "        ESTJ       0.93      0.69      0.79       157\n",
            "        ESTP       0.91      0.72      0.80       595\n",
            "        INFJ       0.58      0.69      0.63      4426\n",
            "        INFP       0.63      0.50      0.56      3612\n",
            "        INTJ       0.62      0.75      0.68      6690\n",
            "        INTP       0.52      0.90      0.66      7604\n",
            "        ISFJ       0.00      0.00      0.00       203\n",
            "        ISFP       0.56      0.02      0.04       242\n",
            "        ISTJ       0.00      0.00      0.00       384\n",
            "        ISTP       0.94      0.13      0.23      1032\n",
            "\n",
            "    accuracy                           0.59     31821\n",
            "   macro avg       0.59      0.31      0.33     31821\n",
            "weighted avg       0.64      0.59      0.54     31821\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QK5EW2VU8YvJ"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}